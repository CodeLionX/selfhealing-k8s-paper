% !TeX root = ../paper.tex
% !TeX encoding = UTF-8
% !TeX spellcheck = en_US

\section{Self-Healing}
  Like in an autonomous system, the main component in a self-healing system is the self-healing manager.
  It runs a control loop with three stages that is a reduced version of the autonomic control loop, also referred to as MAPE-K loop~\cite{ibm_autonomic}.
  The self-healing loop consists of the following three main stages~\cite{PsaierSurvey}:

  \begin{description}
    \item[Detect] The self-healing manager filters the status information about the running system and reports suspicious events and detected degradations.
    \item[Diagnose] The diagnosis stage performs root cause analysis on the received reports from the previous stage and calculates a recovery strategy.
    \item[Recover] In the recovery phase the manager applies the strategies to the system while he avoids any unpredictable side effects.
  \end{description}

  These three stages reflect the definition of self-healing.
  There are different ways, how a software system can be equipped with the above mentioned self-healing capabilities.

  The first approach is a software application with built-in self-healing logic.
  This means that the self-healing manager is within the application code and is able to access internal state and mechanisms.
  This can be an advantage as the application is a white box and the self-healing logic can use detailed status information and even domain knowledge for detection, analysis and recovery.
  At the other hand, this also means that the healing logic is tied to the application increasing coupling and violating the separation of concerns principle.
  If the application starves the self-healing manager may starve as well.
  \citeauthor{ToffettiMicroservices} propose such a system for a microservice architecture.
  They leverage standard methods from distributed systems (\ie consensus algorithms) to assign self-management (includes self-healing) functionality to some nodes of the distributed application.
  The selected nodes form a hierarchy and perform different parts of the self-management logic.
  This means that the self-management logic is distributed in the cluster to overcome the connectedness to the application code.

  The second approach is an external self-healing manager provided as an infrastructural component or as third-party service.
  The self-healing logic runs in isolation from the application code and can therefore treat the application only as a black box and has to use external metrics to judge the application's health.
  It's the current state of the art for monitoring, health management and scaling logic~\cite{ToffettiMicroservices}.
  The external management logic has to be themselves resilient, fault-tolerant, and scalable for being able to heal the application.
  Using third party services or services provided by the infrastructure provider could lead to vendor lock-in.
  There are also open-source alternatives that can be used as middleware between cloud infrastructure and the application, such as \gls{kubernetes}.

\section[Kubernetes]{\gls{kubernetes}}
  \begin{enumerate}
    \item what is \gls{kubernetes}? --> \url{https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/}
    \item architecture and how it works
      \begin{itemize}
        \item master-slave architecture
        \item master runs kube controller manager, API server, etcd, kube scheduler, cloud controller manager
        \item slave (nodes) run kubelet (pod management and health monitoring) and kube proxy (cluster networking), and container runtime (e.g. Docker)
        \item only slaves run application code
      \end{itemize}
    \item \gls{kubernetes} objects\footnote{\url{https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/}} and labels\footnote{\url{https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/}}
    \item pods and containers\footnote{\url{https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/}}
  \end{enumerate}
